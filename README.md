# CAM_attn

条件对齐模块（Condition Alignment Module）是一种用于多条件图像生成的深度学习架构。本项目实现了CAM的增强版本，添加了注意力机制和信息瓶颈理论，以提高生成质量和模型鲁棒性。

## 主要特性

- 多条件输入支持（边缘图、草图、颜色等）
- 基于注意力机制的特征增强
- 信息瓶颈理论指导的特征提取
- 条件对齐和特征融合

## 最新更新

### 两阶段编码器架构与跨条件特征融合

为了提高模型效率并增强不同视觉条件之间的交互，我们对CAMPlus模型进行了以下改进：

1. **两阶段编码器架构**：
   - 前两层为条件特定的独立编码器，专注于提取每种条件的特定特征
   - 后两层为所有条件共享的编码器，促进特征共享和参数效率
   - 这种设计在保持条件特异性的同时，显著减少了模型参数量

2. **跨条件注意力机制**：
   - 实现了跨条件注意力模块，使不同条件的特征能够相互增强
   - 动态调整特征权重，根据其他条件的信息调整当前条件的特征表示
   - 增强了模型对多模态输入的理解能力

3. **模块化解码器**：
   - 将解码器功能封装为独立模块，便于模块化设计和代码复用
   - 保持了与原始解码器相同的功能，确保向后兼容性

4. **特征金字塔增强**：
   - 在共享编码器中集成了特征金字塔网络，增强多尺度特征提取能力
   - 通过跨尺度特征融合，提高了模型对不同尺度特征的利用效率

这些改进使得模型在保持推理时单编码器输入兼容性的同时，提高了参数效率和特征交互能力。

## 模型架构

### CAMPlus

CAMPlus是条件对齐模块的增强版本，主要包含以下组件：

1. **两阶段编码器**：
   - 条件特定编码器：处理不同视觉条件的特定特征
   - 共享编码器：处理来自不同条件特定编码器的特征，提取共享表示

2. **VAE瓶颈层**：基于变分自编码器的瓶颈层，增强特征表示并提供正则化

3. **跨条件注意力**：使用注意力机制融合不同条件的特征，增强条件间的信息交流

4. **解码器**：将编码器特征解码为输出图像

### 注意力机制

本项目实现了多种注意力机制：

- **CBAM**：结合通道注意力和空间注意力
- **自注意力**：基于Transformer设计，捕获长距离依赖关系
- **通道注意力**：基于SE-Net设计，关注通道间的重要性
- **空间注意力**：关注图像的空间区域

### 信息瓶颈理论

基于信息瓶颈理论，模型通过控制信息流动，保留与目标相关的信息，丢弃无关信息，从而提高生成质量和模型鲁棒性。

## 使用方法

### 配置参数

```python
config = {
    'base_channels': 64,  # 基础通道数
    'depth': 4,            # UNet深度
    'attention_type': 'cbam',  # 注意力类型：'cbam', 'self', 'channel', 'spatial'
    'beta': 0.01,          # 信息瓶颈中的权衡参数
    'source_conditions': ['canny', 'sketch', 'color']  # 源条件类型
}
```

### 创建模型

```python
model = CAMPlus(config)
```

### 前向传播

```python
# 准备输入
source_images = {
    'canny': canny_image,    # 边缘图
    'sketch': sketch_image,  # 草图
    'color': color_image     # 颜色图
}
target_img = depth_image    # 目标深度图（可选）

# 前向传播
outputs = model(source_images, target_img)

# 获取结果
results = outputs['outputs']  # 每个条件的输出
```

## 引用

如果您在研究中使用了本项目，请引用以下论文：

```
@article{cam_attn,
  title={Condition Alignment Module with Attention Mechanism for Multi-condition Image Generation},
  author={Author},
  journal={Journal},
  year={2023}
}
```